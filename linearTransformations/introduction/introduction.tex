\documentclass{ximera}

\input{../../preamble.tex}

\title{Linear Transformations}

\begin{document}
\begin{abstract}
  A linear transformation is a function from one vector space to
  another that preserves the addition and scalar multiplication of
  vectors.
\end{abstract}
\maketitle

We prefaced the definition of a vector space with the comment that it was ``one of the two most important definitions in the entire course.''  Here comes the other.  Any capsule summary of linear algebra would have to describe the subject as the interplay of linear transformations and vector spaces.  Here we go.

\begin{definition}[Linear Transformation]
A \dfn{linear transformation}, $\ltdefn{T}{U}{V}$, is a function that carries elements of the vector space $U$ (called the \dfn{domain}) to the vector space $V$ (called the \dfn{codomain}), and which has two additional properties
\begin{enumerate}\item $\lteval{T}{\vect{u}_1+\vect{u}_2}=\lteval{T}{\vect{u}_1}+\lteval{T}{\vect{u}_2}$ for all $\vect{u}_1,\,\vect{u}_2\in U$
\item $\lteval{T}{\alpha\vect{u}}=\alpha\lteval{T}{\vect{u}}$ for all $\vect{u}\in U$ and all $\alpha\in\complexes$
\end{enumerate}
\end{definition}

The two defining conditions in the definition of a linear
transformation should ``feel linear,'' whatever that means.
Conversely, these two conditions could be taken as \textit{exactly}
what it means \textit{to be} linear.  As every vector space property
derives from vector addition and scalar multiplication, so too, every
property of a linear transformation derives from these two defining
properties.  While these conditions may be reminiscent of how we test
subspaces, they really are quite different, so do not confuse the two.

Here are two diagrams that convey the essence of the two defining
properties of a linear transformation.  In each case, begin in the
upper left-hand corner, and follow the arrows around the rectangle to
the lower-right hand corner, taking two different routes and doing the
indicated operations labeled on the arrows.  There are two results
there.  For a linear transformation these two expressions are always
equal.
% \begin{image}
% \begin{tikzpicture}[ampersand replacement=\&]
% \matrix (m) [matrix of math nodes, row sep=5em, column sep=10em, text height=1.5ex, text depth=0.25ex]
% { \vect{u}_1,\,\vect{u}_2 \& T(\vect{u}_1),\,T(\vect{u}_2) \\
% \vect{u}_1+\vect{u}_2 \& T(\vect{u}_1+\vect{u}_2)=T(\vect{u}_1)+T(\vect{u}_2)\\};
% \path[->]
% (m-1-1) edge[thick] node[auto] {$T$} (m-1-2)
% (m-1-2) edge[thick] node[auto] {$+$} (m-2-2)
% (m-1-1) edge[thick] node[auto] {$+$} (m-2-1)
% (m-2-1) edge[thick] node[auto] {$T$} (m-2-2);
% \end{tikzpicture}
% \end{image}
% \begin{image}
% \begin{tikzpicture}[ampersand replacement=\&]
% \matrix (m) [matrix of math nodes, row sep=5em, column sep=10em, text height=1.5ex, text depth=0.25ex]
% { \vect{u} \& \lteval{T}{\vect{u}} \\
% \alpha\vect{u} \& \lteval{T}{\alpha\vect{u}}=\alpha\lteval{T}{\vect{u}}\\};
% \path[->]
% (m-1-1) edge[thick] node[auto] {$T$}      (m-1-2)
% (m-1-2) edge[thick] node[auto] {$\alpha$} (m-2-2)
% (m-1-1) edge[thick] node[auto] {$\alpha$} (m-2-1)
% (m-2-1) edge[thick] node[auto] {$T$}      (m-2-2);
% \end{tikzpicture}
% \end{image}

A couple of words about notation.  $T$ is the \textit{name} of the
linear transformation, and should be used when we want to discuss the
function as a whole.  $\lteval{T}{\vect{u}}$ is how we talk about the
output of the function, it is a vector in the vector space $V$.  When
we write
$\lteval{T}{\vect{x}+\vect{y}}=\lteval{T}{\vect{x}}+\lteval{T}{\vect{y}}$, the
plus sign on the left is the operation of vector addition in the
vector space $U$, since $\vect{x}$ and $\vect{y}$ are elements of $U$.
The plus sign on the right is the operation of vector addition in the
vector space $V$, since $\lteval{T}{\vect{x}}$ and $\lteval{T}{\vect{y}}$ are
elements of the vector space $V$.  These two instances of vector
addition might be wildly different.

Let us examine several examples and begin to form a catalog of known linear transformations to work with.

\begin{example}[A linear transformation]

Define $\ltdefn{T}{\complex{3}}{\complex{2}}$ by describing the output of the function for a generic input with the formula
\[
\lteval{T}{\colvector{x_1\\x_2\\x_3}}=\colvector{2x_1+x_3\\-4x_2}
\]
and check the two defining properties.
\begin{align*}
\lteval{T}{\vect{x}+\vect{y}}
&=\lteval{T}{\colvector{x_1\\x_2\\x_3}+\colvector{y_1\\y_2\\y_3}}\\
&=\lteval{T}{\colvector{x_1+y_1\\x_2+y_2\\x_3+y_3}}\\
&=\colvector{2(x_1+y_1)+(x_3+y_3)\\-4(x_2+y_2)}\\
&=\colvector{(2x_1+x_3)+(2y_1+y_3)\\-4x_2+(-4)y_2}\\
&=\colvector{2x_1+x_3\\-4x_2}+\colvector{2y_1+y_3\\-4y_2}\\
&=\lteval{T}{\colvector{x_1\\x_2\\x_3}}+\lteval{T}{\colvector{y_1\\y_2\\y_3}}\\
&=\lteval{T}{\vect{x}}+\lteval{T}{\vect{y}}
\end{align*}
and
\begin{align*}
\lteval{T}{\alpha\vect{x}}
&=\lteval{T}{\alpha\colvector{x_1\\x_2\\x_3}}\\
&=\lteval{T}{\colvector{\alpha x_1\\\alpha x_2\\\alpha x_3}}\\
&=\colvector{2(\alpha x_1)+(\alpha x_3)\\-4(\alpha x_2)}\\
&=\colvector{\alpha(2x_1+x_3)\\\alpha(-4x_2)}\\
&=\alpha\colvector{2x_1+x_3\\-4x_2}\\
&=\alpha\lteval{T}{\colvector{x_1\\x_2\\x_3}}\\
&=\alpha\lteval{T}{\vect{x}}\\
\end{align*}

So $T$ is a linear transformation.
\end{example}

It can be just as instructive to look at functions that are
\textit{not} linear transformations.  Since the defining conditions
must be true for \textit{all} vectors and scalars, it is enough to
find just one situation where the properties fail.

\begin{example}[Not a linear transformation]

Define $\ltdefn{S}{\complex{3}}{\complex{3}}$ by
\[
\lteval{S}{\colvector{x_1\\x_2\\x_3}}=\colvector{4x_1+2x_2\\0\\x_1+3x_3-2}
\]

This function ``looks'' linear, but consider
\begin{align*}
3\,\lteval{S}{\colvector{1\\2\\3}}&=3\,\colvector{8\\0\\8}=\colvector{24\\0\\24}
\end{align*}
while
\begin{align*}
\lteval{S}{3\,\colvector{1\\2\\3}}&=\lteval{S}{\colvector{3\\6\\9}}=\colvector{24\\0\\28}
\end{align*}


So the second required property fails for the choice of $\alpha=3$ and $\vect{x}=\colvector{1\\2\\3}$ and by \ref{definition:LT}, $S$ is not a linear transformation.  It is just about as easy to find an example where the first defining property fails (try it!).  Notice that it is the ``-2'' in the third component of the definition of $S$ that prevents the function from being a linear transformation.

\end{example}

\begin{question}
Does
\[
\ltdefn{T}{P_2}{\complex{2}},\quad \lteval{T}{a+bx+cx^2}=\colvector{2a-b\\b+c}
\]
defin a linear transformation?

\begin{hint}Check the two conditions of \ref{definition:LT}.\end{hint}
\begin{hint}
\begin{align*}
\lteval{T}{\vect{u}+\vect{v}}
&=\lteval{T}{\left(a+bx+cx^2\right)+\left(d+ex+fx^2\right)}\\
&=\lteval{T}{\left(a+d\right)+\left(b+e\right)x+\left(c+f\right)x^2}\\
&=\colvector{2(a+d)-(b+e)\\(b+e)+(c+f)}\\
&=\colvector{(2a-b)+(2d-e)\\(b+c)+(e+f)}\\
&=\colvector{2a-b\\b+c}+\colvector{2d-e\\e+f}\\
&=\lteval{T}{\vect{u}}+\lteval{T}{\vect{v}}
\end{align*}
\end{hint}
\begin{hint}
\begin{align*}
\lteval{T}{\alpha\vect{u}}
&=\lteval{T}{\alpha\left(a+bx+cx^2\right)}\\
&=\lteval{T}{\left(\alpha a\right)+\left(\alpha b\right)x+\left(\alpha c\right)x^2}\\
&=\colvector{2(\alpha a)-(\alpha b)\\(\alpha b)+(\alpha c)}\\
&=\colvector{\alpha(2a-b)\\\alpha(b+c)}\\
&=\alpha\colvector{2a-b\\b+c}\\
&=\alpha\lteval{T}{\vect{u}}
\end{align*}
\end{hint}
\begin{hint}
So $T$ is indeed a linear transformation.
\end{hint}

\begin{multipleChoice}
\choice[correct]{Yes}
\choice{No}
\end{multipleChoice}
\end{question}

\begin{example}[Linear transformation, polynomials to matrices]

Define a linear transformation $\ltdefn{T}{P_3}{M_{22}}$ by
\[
\lteval{T}{a+bx+cx^2+dx^3}=\begin{bmatrix}a+b&a-2c\\d&b-d\end{bmatrix}
\]

We verify the two defining conditions of a linear transformation.
\begin{align*}
\lteval{T}{\vect{x}+\vect{y}}&=
\lteval{T}{(a_1+b_1x+c_1x^2+d_1x^3)+(a_2+b_2x+c_2x^2+d_2x^3)}\\
&=\lteval{T}{(a_1+a_2)+(b_1+b_2)x+(c_1+c_2)x^2+(d_1+d_2)x^3}\\
&=\begin{bmatrix}
(a_1+a_2)+(b_1+b_2)&(a_1+a_2)-2(c_1+c_2)\\
d_1+d_2&(b_1+b_2)-(d_1+d_2)
\end{bmatrix}\\
&=\begin{bmatrix}
(a_1+b_1)+(a_2+b_2)&(a_1-2c_1)+(a_2-2c_2)\\
d_1+d_2&(b_1-d_1)+(b_2-d_2)
\end{bmatrix}\\
&=\begin{bmatrix}a_1+b_1&a_1-2c_1\\d_1&b_1-d_1\end{bmatrix}+
     \begin{bmatrix}a_2+b_2&a_2-2c_2\\d_2&b_2-d_2\end{bmatrix}\\
&=\lteval{T}{a_1+b_1x+c_1x^2+d_1x^3}+\lteval{T}{a_2+b_2x+c_2x^2+d_2x^3}\\
&=\lteval{T}{\vect{x}}+\lteval{T}{\vect{y}}
\end{align*}
and
\begin{align*}
\lteval{T}{\alpha\vect{x}}&=\lteval{T}{\alpha(a+bx+cx^2+dx^3)}\\
&=\lteval{T}{(\alpha a)+(\alpha b)x+(\alpha c)x^2+(\alpha d)x^3}\\
&=\begin{bmatrix}
(\alpha a)+(\alpha b)&(\alpha a)-2(\alpha c)\\
\alpha d&(\alpha b)-(\alpha d)
\end{bmatrix}\\
&=\begin{bmatrix}
\alpha(a+b)&\alpha(a-2c)\\
\alpha d&\alpha(b-d)
\end{bmatrix}\\
&=\alpha\begin{bmatrix}a+b&a-2c\\d&b-d\end{bmatrix}\\
&=\alpha\lteval{T}{a+bx+cx^2+dx^3}\\
&=\alpha\lteval{T}{\vect{x}}
\end{align*}

So $T$ is a linear transformation.
\end{example}

\begin{example}[Linear transformation, polynomials to polynomials]

Define a function $\ltdefn{S}{P_4}{P_5}$ by
\[
S(p(x))=(x-2)p(x)
\]


Then
\begin{align*}
\lteval{S}{p(x)+q(x)}&=(x-2)(p(x)+q(x))\\
&=(x-2)p(x)+(x-2)q(x)=\lteval{S}{p(x)}+\lteval{S}{q(x)}\\
\lteval{S}{\alpha p(x)}&=(x-2)(\alpha p(x))=(x-2)\alpha p(x)=\alpha(x-2)p(x)=\alpha\lteval{S}{p(x)}
\end{align*}



So by \ref{definition:LT}, $S$ is a linear transformation.


\end{example}

Linear transformations have many amazing properties, which we will
investigate through the next few activities.  However, as a taste of
things to come, here is a theorem we can prove now and put to use
immediately.


\begin{theorem}[Linear Transformations Take Zero to Zero]
\label{theorem:LTTZZ}

Suppose $\ltdefn{T}{U}{V}$ is a linear transformation.  Then $\lteval{T}{\zerovector}=\zerovector$.

\begin{proof}
  The two zero vectors in the conclusion of the theorem are different.
  The first is from $U$ while the second is from $V$.  We will
  subscript the zero vectors in this proof to highlight the
  distinction.  Think about your objects.  (This proof is contributed
  by markshoemaker).
  \begin{align*}
    \lteval{T}{\zerovector_U}
    &=\lteval{T}{0\zerovector_U}
    &&\ref{theorem:ZSSM}\text{ in }U\\
    &=0\lteval{T}{\zerovector_U}
    &&\ref{definition:LT}\\
    &=\zerovector_V
    &&\ref{theorem:ZSSM}\text{ in }V
  \end{align*}
\end{proof}
\end{theorem}

Return to \ref{example:NLT} and compute $\lteval{S}{\colvector{0\\0\\0}}=\colvector{0\\0\\-2}$ to quickly see again that $S$ is not a linear transformation, while in \ref{example:LTPM}  compute
\begin{align*}
\lteval{S}{0+0x+0x^2+0x^3}&=\begin{bmatrix}0&0\\0&0\end{bmatrix}
\end{align*}
as an example of \ref{theorem:LTTZZ} at work.

\end{document}
